import os
import logging
import pandas as pd
import json
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
from threading import Thread
import random
from sentence_transformers import SentenceTransformer, util
import requests
import torch
import numpy as np
import hashlib
import re
import time
from typing import List, Dict, Any
from collections import Counter

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

HF_API_TOKEN = os.getenv('HF_API_TOKEN')
HF_API_URL = "https://router.huggingface.co/hf-inference/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
headers = {
    "Authorization": f"Bearer {HF_API_TOKEN}",
}

flask_app = Flask(__name__)
CORS(flask_app)

def check_hf_token():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å HF_API_TOKEN"""
    if not HF_API_TOKEN:
        print("‚ùå HF_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    
    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–∫–µ–Ω–∞
    try:
        test_response = requests.get(
            "https://huggingface.co/api/whoami",
            headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
            timeout=10
        )
        if test_response.status_code == 200:
            print("‚úÖ HF_API_TOKEN –≤–∞–ª–∏–¥–µ–Ω")
            return True
        else:
            print(f"‚ùå HF_API_TOKEN –Ω–µ–≤–∞–ª–∏–¥–µ–Ω: {test_response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ HF_API_TOKEN: {e}")
        return False

# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
check_hf_token()

class RouteExplainer:
    def __init__(self, api_token=None, model_name="IlyaGusev/saiga_llama3_8b:featherless-ai"):
        self.model_name = model_name
        self.api_token = api_token
        self.api_url = "https://router.huggingface.co/v1/chat/completions"
        self._cache = {}
        self._cached_prompts = self._precompile_prompts()
        self._category_mapping = {
            '1': '–ü–∞–º—è—Ç–Ω–∏–∫–∏ –∏ —Å–∫—É–ª—å–ø—Ç—É—Ä—ã',
            '2': '–ü–∞—Ä–∫–∏ –∏ –ø—Ä–∏—Ä–æ–¥–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã', 
            '3': '–¢–∞–∫—Ç–∏–ª—å–Ω—ã–µ –º–∞–∫–µ—Ç—ã',
            '4': '–Ω–∞–±–µ—Ä–µ–∂–Ω—ã–µ',
            '5': '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∑–¥–∞–Ω–∏—è',
            '6': '–æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ü–µ–Ω—Ç—Ä—ã',
            '7': '–º—É–∑–µ–∏',
            '8': '—Ç–µ–∞—Ç—Ä—ã –∏ —Ñ–∏–ª–∞—Ä–º–æ–Ω–∏–∏',
            '10': '–º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–æ',
            '11': '—Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã –∏ –∫–∞—Ñ–µ',
            '12': '–∫–æ—Ñ–µ–π–Ω–∏', 
            '13': '–∫–æ–Ω–¥–∏—Ç–µ—Ä—Å–∫–∏–µ –∏ –ø–µ–∫–∞—Ä–Ω–∏',
            '14': '—Ç–æ—Ä–≥–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã',
            '15': '–º–µ—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–π'
        }
        
        self._fallback_reasons = {
            '1': "–≤—ã–±—Ä–∞–Ω –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ø–∞–º—è—Ç–Ω–∏–∫, –æ—Ç—Ä–∞–∂–∞—é—â–∏–π –∫—É–ª—å—Ç—É—Ä–Ω–æ–µ –Ω–∞—Å–ª–µ–¥–∏–µ –≥–æ—Ä–æ–¥–∞",
            '2': "–≤–∫–ª—é—á–µ–Ω –≤ –º–∞—Ä—à—Ä—É—Ç –∫–∞–∫ –ø—Ä–∏—Ä–æ–¥–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è –æ—Ç–¥—ã—Ö–∞ –∏ –ø—Ä–æ–≥—É–ª–æ–∫", 
            '3': "–¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ –¥–æ—Å—Ç—É–ø–Ω—ã–π –º–∞–∫–µ—Ç –¥–ª—è —Ç–∞–∫—Ç–∏–ª—å–Ω–æ–≥–æ –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è",
            '4': "–≤—ã–±—Ä–∞–Ω –∏–∑-–∑–∞ –∂–∏–≤–æ–ø–∏—Å–Ω–æ–π –Ω–∞–±–µ—Ä–µ–∂–Ω–æ–π —Å –∫—Ä–∞—Å–∏–≤—ã–º–∏ –≤–∏–¥–∞–º–∏",
            '5': "–≤–∫–ª—é—á–µ–Ω –∫–∞–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å –±–æ–≥–∞—Ç–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π",
            '6': "–¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –∏ –æ—Ç–¥—ã—Ö–∞",
            '7': "–≤—ã–±—Ä–∞–Ω –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –º—É–∑–µ–π —Å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º–∏ —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è–º–∏",
            '8': "–≤–∫–ª—é—á–µ–Ω –∫–∞–∫ –∫—É–ª—å—Ç—É—Ä–Ω–æ–µ —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–ª—è –¥–æ—Å—É–≥–∞ –∏ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–π",
            '10': "–¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –º–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∏—Å–∫—É—Å—Å—Ç–≤–∞",
            '11': "–≤—ã–±—Ä–∞–Ω –∫–∞–∫ –∑–∞–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –ø–∏—Ç–∞–Ω–∏—è –∏ –æ—Ç–¥—ã—Ö–∞",
            '12': "–≤–∫–ª—é—á–µ–Ω –∫–∞–∫ —É—é—Ç–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –∫–æ—Ñ–µ-–±—Ä–µ–π–∫–∞ –∏ –≤—Å—Ç—Ä–µ—á",
            '13': "–¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ –∫–æ–Ω–¥–∏—Ç–µ—Ä—Å–∫–∞—è —Å–æ —Å–≤–µ–∂–µ–π –≤—ã–ø–µ—á–∫–æ–π –∏ —Å–ª–∞–¥–æ—Å—Ç—è–º–∏", 
            '14': "–≤—ã–±—Ä–∞–Ω –∫–∞–∫ —Ç–æ—Ä–≥–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Å —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –º–∞–≥–∞–∑–∏–Ω–∞–º–∏",
            '15': "–≤–∫–ª—é—á–µ–Ω –∫–∞–∫ —Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç–¥—ã—Ö–∞"
        }
        
        self._russian_pattern = re.compile(r'^[–∞-—è–ê-–Ø—ë–Å0-9\s\.,!?;-]+$')
    
    def _query_huggingface(self, prompt, max_retries=3):
        headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model_name,
            "messages": [
                {"role": "system", "content": "–¢—ã ‚Äî —É–º–Ω—ã–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 800,
            "temperature": 0.7,
            "top_p": 0.9,
        }

        for attempt in range(max_retries):
            try:
                response = requests.post(self.api_url, headers=headers, json=payload, timeout=120)
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        return result["choices"][0]["message"]["content"]
                elif response.status_code == 503:
                    wait_time = (attempt + 1) * 30
                    print(f"‚è≥ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –∂–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
                    if response.status_code in [400, 401, 404]:
                        break
            except requests.exceptions.Timeout:
                print(f"‚è∞ –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                continue
            except Exception as e:
                print(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {e}")
                continue

        return ""
    
    def _precompile_prompts(self):
        base_prompt = """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤. –°–æ–∑–¥–∞–π —Å–≤—è–∑–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç –ø–æ –ù–∏–∂–Ω–µ–º—É –ù–æ–≤–≥–æ—Ä–æ–¥—É. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –†–£–°–°–ö–ò–ô –Ø–ó–´–ö.

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Å—Ç–∞ –¥–ª—è –ø–æ—Å–µ—â–µ–Ω–∏—è:
{places}

–ò–Ω—Ç–µ—Ä–µ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {interests}
–û–±—â–µ–µ –≤—Ä–µ–º—è –º–∞—Ä—à—Ä—É—Ç–∞: {duration} –º–∏–Ω—É—Ç
–ù–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞: {location}

–°–æ–∑–¥–∞–π –º–∞—Ä—à—Ä—É—Ç, –∫–æ—Ç–æ—Ä—ã–π –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–æ–µ–¥–∏–Ω—è–µ—Ç —ç—Ç–∏ –º–µ—Å—Ç–∞. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—Ç–∞ –¥–∞–π –ö–†–ê–¢–ö–û–ï –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ - –ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ –æ–Ω–æ –±—ã–ª–æ –≤—ã–±—Ä–∞–Ω–æ —Å —É—á–µ—Ç–æ–º –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–µ—Å—Ç–∞.

–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π:
{{
"route_name": "–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º",
"total_duration": –æ–±—â–µ–µ_–≤—Ä–µ–º—è,
"timeline": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∞",
"explanation": "–æ–±—â–µ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–∞—Ä—à—Ä—É—Ç–∞",
"places": [
  {{
    "name": "–Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞",
    "order": 1,
    "duration": 30,
    "reason": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω–æ —ç—Ç–æ –º–µ—Å—Ç–æ —Å —É—á–µ—Ç–æ–º –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"
  }}
]
}}"""
        return {'base': base_prompt}
    
    def _is_russian_text(self, text):
        if not text or not isinstance(text, str):
            return False
        sample = text[:100]
        return bool(self._russian_pattern.match(sample.replace('"', '').replace("'", "")))
    
    def _clean_russian_text(self, text):
        if not text:
            return ""
        cleaned = re.sub(r'[^–∞-—è–ê-–Ø—ë–Å0-9\s\.,!?;-]', '', str(text))
        return cleaned.strip()
    
    def _map_category(self, category_id):
        return self._category_mapping.get(str(category_id), '–¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å')
    
    def _get_fallback_reason(self, place, user_interests):
        category_id = str(place.get('category_id', ''))
        base_reason = self._fallback_reasons.get(category_id, "–≤—ã–±—Ä–∞–Ω–æ –∫–∞–∫ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –ø–æ—Å–µ—â–µ–Ω–∏—è")
        
        if user_interests:
            interests_str = ' '.join(user_interests).lower()
            
            if any(word in interests_str for word in ['–∏—Å—Ç–æ—Ä–∏', '–º—É–∑–µ–π', '–ø–∞–º—è—Ç–Ω–∏–∫']):
                if category_id in ['1', '5', '7']:
                    return f"–≤—ã–±—Ä–∞–Ω –ø–æ—Ç–æ–º—É —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–µ–º—É –∏–Ω—Ç–µ—Ä–µ—Å—É –∫ –∏—Å—Ç–æ—Ä–∏–∏: {base_reason}"
                    
            elif any(word in interests_str for word in ['–µ–¥–∞', '–∫—É—Ö–Ω', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–∫–æ—Ñ–µ', '–ø–∏—Ç–∞–Ω–∏–µ']):
                if category_id in ['11', '12', '13']:
                    return f"–≤–∫–ª—é—á–µ–Ω –∫–∞–∫ –≥–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ –º–µ—Å—Ç–æ, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –≤–∞—à–∏–º –∏–Ω—Ç–µ—Ä–µ—Å–∞–º: {base_reason}"
                    
            elif any(word in interests_str for word in ['–ø–æ–∫—É–ø', '—à–æ–ø–ø–∏–Ω–≥', '—Ç–æ—Ä–≥–æ–≤']):
                if category_id == '14':
                    return f"–¥–æ–±–∞–≤–ª–µ–Ω –¥–ª—è —à–æ–ø–∏–Ω–≥–∞ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É: {base_reason}"
                    
            elif any(word in interests_str for word in ['—Ä–∞–∑–≤–ª–µ–∫', '–æ—Ç–¥—ã—Ö', '–¥–æ—Å—É–≥', '–∫–∏–Ω–æ']):
                if category_id in ['15', '2', '6']:
                    return f"–≤—ã–±—Ä–∞–Ω –¥–ª—è —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–π –∏ –æ—Ç–¥—ã—Ö–∞: {base_reason}"
        
        return base_reason

    def _fix_json_errors(self, json_str):
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ JSON –æ—Ç –º–æ–¥–µ–ª–∏"""
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–∞–ø—è—Ç—ã–µ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –º–∞—Å—Å–∏–≤–∞
        json_str = re.sub(r'"\s*\n\s*"', '", "', json_str)
        json_str = re.sub(r'"\s*}\s*"', '"}, "', json_str)
        json_str = re.sub(r'"\s*}\s*{', '"}, {', json_str)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–∞–ø—è—Ç—ã–µ –º–µ–∂–¥—É —Å–≤–æ–π—Å—Ç–≤–∞–º–∏ –æ–±—ä–µ–∫—Ç–∞
        json_str = re.sub(r'"\s*\n\s*"', '",\n"', json_str)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–ø—è—Ç—ã–µ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        return json_str

    def create_route(self, places, user_interests, total_duration, current_location):
        cache_key = self._generate_cache_key(places, user_interests, total_duration, current_location)
        
        if cache_key in self._cache:
            return self._cache[cache_key]
        
        places_text = self._format_places_optimized(places)
        
        prompt = self._create_optimized_prompt(places_text, user_interests, total_duration, current_location)
        
        print(f"üìù –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –≤ –º–æ–¥–µ–ª—å...")
        
        try:
            response_text = self._query_huggingface(prompt)
            
            if response_text:
                print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏: {response_text[:200]}...")
                result = self._parse_and_validate_response(response_text, places, user_interests)
            else:
                print("‚ö†Ô∏è  –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç")
                result = self._get_optimized_fallback_route(places, user_interests, total_duration)
            
        except Exception as e:
            print(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–∞—Ä—à—Ä—É—Ç–∞: {e}")
            result = self._get_optimized_fallback_route(places, user_interests, total_duration)
        
        self._cache[cache_key] = result
        return result

    def _generate_cache_key(self, places, user_interests, total_duration, current_location):
        places_hash = hashlib.md5(
            ''.join(sorted([p.get('name', '') + str(p.get('category_id', '')) for p in places])).encode()
        ).hexdigest()[:8]
        
        interests_hash = hashlib.md5(
            str(sorted(user_interests)).encode()
        ).hexdigest()[:6]
        
        return f"{places_hash}_{interests_hash}_{total_duration}"

    def _format_places_optimized(self, places):
        if not places:
            return "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Å—Ç"
            
        formatted_places = []
        for i, p in enumerate(places[:5], 1):
            place_name = p.get('name', f'–ú–µ—Å—Ç–æ {i}')
            category_id = str(p.get('category_id', ''))
            category_name = self._map_category(category_id)
            
            place_str = f"{i}. {place_name} ({category_name})"
            formatted_places.append(place_str)
        
        return "\n".join(formatted_places)

    def _create_optimized_prompt(self, places_text, user_interests, total_duration, current_location):
        prompt_template = self._cached_prompts['base']
        
        return prompt_template.format(
            places=places_text,
            interests=user_interests,
            duration=total_duration,
            location=current_location
        )

    def _parse_and_validate_response(self, response_text, places, user_interests):
        print(f"üîç –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏...")
        
        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON —Å –ø–æ–º–æ—â—å—é regex
        json_pattern = r'\{[^{}]*\{[^{}]*\}[^{}]*\}'  # –ò—â–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        matches = re.finditer(json_pattern, response_text, re.DOTALL)
        
        json_str = None
        for match in matches:
            try:
                potential_json = match.group()
                # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                json.loads(potential_json)
                json_str = potential_json
                break
            except:
                continue
        
        if not json_str:
            # Fallback: –∏—â–µ–º –ø—Ä–æ—Å—Ç–æ–π JSON
            start = response_text.find('{')
            end = response_text.rfind('}') + 1
            if start != -1 and end != 0:
                json_str = response_text[start:end]
        
        if not json_str:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ –æ—Ç–≤–µ—Ç–µ")
            return self._get_optimized_fallback_route(places, user_interests, 120)
        
        print(f"üìÑ –ù–∞–π–¥–µ–Ω JSON: {json_str[:200]}...")
        
        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ—á–∏–Ω–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ JSON
            json_str = self._fix_json_errors(json_str)
            result = json.loads(json_str)
            
            if 'places' not in result or not isinstance(result['places'], list):
                print("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON")
                return self._get_optimized_fallback_route(places, user_interests, 120)
            
            if 'route_name' in result:
                if not self._is_russian_text(result['route_name']):
                    result['route_name'] = self._generate_route_name(places, user_interests)
                else:
                    result['route_name'] = self._clean_russian_text(result['route_name'])
            
            valid_places = []
            for i, place in enumerate(result['places'][:4], 1):
                if 'name' not in place:
                    continue
                    
                place['name'] = self._clean_russian_text(place.get('name', f'–ú–µ—Å—Ç–æ {i}'))
                
                if 'reason' not in place or not self._is_russian_text(place['reason']):
                    original_place = next((p for p in places if p.get('name') == place['name']), None)
                    place['reason'] = self._get_fallback_reason(original_place, user_interests) if original_place else "–≤—ã–±—Ä–∞–Ω–æ –∫–∞–∫ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –ø–æ—Å–µ—â–µ–Ω–∏—è"
                else:
                    place['reason'] = self._clean_russian_text(place['reason'])
                
                place['order'] = i
                place['duration'] = place.get('duration', 30)
                
                valid_places.append(place)
            
            if not valid_places:
                print("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –º–µ—Å—Ç –≤ –º–∞—Ä—à—Ä—É—Ç–µ")
                return self._get_optimized_fallback_route(places, user_interests, 120)
            
            result['places'] = valid_places
            
            if 'total_duration' not in result:
                result['total_duration'] = sum(p.get('duration', 30) for p in valid_places)
            
            result['total_duration'] = min(result['total_duration'], 1440)
            
            if 'timeline' not in result:
                result['timeline'] = f"–ú–∞—Ä—à—Ä—É—Ç –∏–∑ {len(valid_places)} –º–µ—Å—Ç"
            else:
                result['timeline'] = self._clean_russian_text(result['timeline'])
                
            if 'explanation' not in result:
                result['explanation'] = "–ú–∞—Ä—à—Ä—É—Ç —Å–æ—Å—Ç–∞–≤–ª–µ–Ω —Å —É—á–µ—Ç–æ–º –≤–∞—à–∏—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤"
            else:
                result['explanation'] = self._clean_russian_text(result['explanation'])
            
            print("‚úÖ –ú–∞—Ä—à—Ä—É—Ç —É—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")
            return result
            
        except (json.JSONDecodeError, KeyError) as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {e}")
            return self._get_optimized_fallback_route(places, user_interests, 120)

    def _get_optimized_fallback_route(self, places, user_interests, total_duration):
        print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –º–∞—Ä—à—Ä—É—Ç–∞")
        
        if not places:
            return self._get_minimal_fallback_route()
        
        selected_places = places[:4]
        
        if len(selected_places) == 0:
            return self._get_minimal_fallback_route()
            
        place_duration = max(25, total_duration // len(selected_places))
        
        route_places = []
        for i, place in enumerate(selected_places, 1):
            route_places.append({
                "name": self._clean_russian_text(place.get('name', f'–ú–µ—Å—Ç–æ {i}')),
                "order": i,
                "duration": place_duration,
                "reason": self._get_fallback_reason(place, user_interests)
            })
        
        route_name = self._generate_route_name(selected_places, user_interests)
        
        return {
            "route_name": route_name,
            "total_duration": min(place_duration * len(route_places), 1440),
            "places": route_places,
            "timeline": f"–ü–æ—Å–µ—â–µ–Ω–∏–µ {len(route_places)} –º–µ—Å—Ç",
            "explanation": f"–ú–∞—Ä—à—Ä—É—Ç —Å–æ—Å—Ç–∞–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å —É—á–µ—Ç–æ–º –≤–∞—à–∏—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤: {', '.join(user_interests) if user_interests else '–æ—Å–Ω–æ–≤–Ω—ã–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏'}"
        }

    def _generate_route_name(self, places, user_interests):
        if not places:
            return "–û–±–∑–æ—Ä–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç –ø–æ –ù–∏–∂–Ω–µ–º—É –ù–æ–≤–≥–æ—Ä–æ–¥—É"
        
        categories = [str(p.get('category_id', '')) for p in places if p.get('category_id')]
        
        category_themes = {
            '1': "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π",
            '2': "–ü—Ä–∏—Ä–æ–¥–Ω—ã–π",
            '5': "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π", 
            '7': "–ú—É–∑–µ–π–Ω—ã–π",
            '11': "–ì–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π",
            '12': "–ö–æ—Ñ–µ–π–Ω—ã–π",
            '13': "–ö–æ–Ω–¥–∏—Ç–µ—Ä—Å–∫–∏–π",
            '14': "–®–æ–ø–∏–Ω–≥",
            '15': "–†–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π"
        }
        
        if categories:
            most_common = Counter(categories).most_common(1)[0][0]
            if most_common in category_themes:
                return f"{category_themes[most_common]} –º–∞—Ä—à—Ä—É—Ç –ø–æ –ù–∏–∂–Ω–µ–º—É –ù–æ–≤–≥–æ—Ä–æ–¥—É"
        
        if user_interests:
            interests_str = ' '.join(user_interests).lower()
            if any(word in interests_str for word in ['–∏—Å—Ç–æ—Ä–∏', '–º—É–∑–µ–π']):
                return "–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –º–∞—Ä—à—Ä—É—Ç –ø–æ –≥–æ—Ä–æ–¥—É"
            elif any(word in interests_str for word in ['–µ–¥–∞', '–∫—É—Ö–Ω', '—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–∫–æ—Ñ–µ']):
                return "–ì–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π –º–∞—Ä—à—Ä—É—Ç"
            elif any(word in interests_str for word in ['–ø–æ–∫—É–ø', '—à–æ–ø–ø–∏–Ω–≥']):
                return "–¢–æ—Ä–≥–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç"
            elif any(word in interests_str for word in ['—Ä–∞–∑–≤–ª–µ–∫', '–æ—Ç–¥—ã—Ö']):
                return "–†–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç"
        
        return "–û–±–∑–æ—Ä–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç –ø–æ –ù–∏–∂–Ω–µ–º—É –ù–æ–≤–≥–æ—Ä–æ–¥—É"

    def _get_minimal_fallback_route(self):
        return {
            "route_name": "–ë–∞–∑–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç –ø–æ –≥–æ—Ä–æ–¥—É",
            "total_duration": 90,
            "places": [
                {
                    "name": "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                    "order": 1,
                    "duration": 90,
                    "reason": "–≤—ã–±—Ä–∞–Ω—ã –¥–ª—è –æ–±–∑–æ—Ä–∞ –≥–ª–∞–≤–Ω—ã—Ö –º–µ—Å—Ç –≥–æ—Ä–æ–¥–∞"
                }
            ],
            "timeline": "–ü—Ä–æ–≥—É–ª–∫–∞ –ø–æ —Ü–µ–Ω—Ç—Ä—É",
            "explanation": "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–∏—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–µ –º–µ—Å—Ç–∞ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞"
        }

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RouteExplainer
route_explainer = RouteExplainer(api_token=HF_API_TOKEN)

def get_bot_token():
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        load_dotenv()
        token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        raise ValueError("TELEGRAM_BOT_TOKEN was not found!")
    return token

def load_dataset():
    try:
        ds = pd.read_excel('dataset.xlsx')
        print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(ds)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìä –°—Ç–æ–ª–±—Ü—ã –¥–∞—Ç–∞—Å–µ—Ç–∞: {ds.columns.tolist()}")
        print(f"üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ category_id: {ds['category_id'].unique()}")
        return ds
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ - {e}")
        return None

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton("–û—Ç–∫—Ä—ã—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", web_app={"url": "https://anansypineapple.github.io/miniApp-maps/"})]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç, –¥—Ä—É–≥! –ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ —á—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ!",
                                    reply_markup=reply_markup)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton("–û—Ç–∫—Ä—ã—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", web_app={"url": "https://anansypineapple.github.io/miniApp-maps/"})]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("–ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ!", reply_markup=reply_markup)

def get_embeddings(texts):
    if not HF_API_TOKEN:
        print("‚ùå –û—à–∏–±–∫–∞: HF_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return None
        
    if isinstance(texts, str):
        texts = [texts]
    
    try:
        print(f"üîÑ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Sentence Transformer API –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤")
        response = requests.post(
            HF_API_URL,
            headers=headers,
            json={"inputs": texts, "options": {"wait_for_model": True}},
            timeout=60  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
        )
        
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
            
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
            if isinstance(data, list):
                if all(isinstance(item, list) for item in data):
                    return data  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: [[emb1], [emb2], ...]
                elif all(isinstance(item, (int, float)) for item in data):
                    return [data]  # –û–¥–∏–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥ –∫–∞–∫ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
                elif isinstance(data[0], dict) and "embedding" in data[0]:
                    return [item["embedding"] for item in data]  # –§–æ—Ä–º–∞—Ç —Å –∫–ª—é—á–æ–º "embedding"
            
            # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω, –ª–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {type(data)}")
            if isinstance(data, dict):
                print(f"üìä –ö–ª—é—á–∏ –≤ –æ—Ç–≤–µ—Ç–µ: {data.keys()}")
            return None
            
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        print(f"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
        return None

category_names = [
    "–ü–∞–º—è—Ç–Ω–∏–∫–∏ –∏ —Å–∫—É–ª—å–ø—Ç—É—Ä—ã",
    "–ü–∞—Ä–∫–∏, —Å–∫–≤–µ—Ä—ã –∏ –∑–æ–Ω—ã –æ—Ç–¥—ã—Ö–∞", 
    "–ú–∞–∫–µ—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤",
    "–ù–∞–±–µ—Ä–µ–∂–Ω—ã–µ",
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∑–¥–∞–Ω–∏—è",
    "–ö—É–ª—å—Ç—É—Ä–Ω–æ-–¥–æ—Å—É–≥–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏",
    "–ú—É–∑–µ–∏ –∏ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞",
    "–¢–µ–∞—Ç—Ä—ã –∏ —Ñ–∏–ª–∞—Ä–º–æ–Ω–∏–∏",
    "–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
    "–ú–æ–Ω—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ-–¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–æ",
    "–†–µ—Å—Ç–æ—Ä–∞–Ω—ã –∏ –∫–∞—Ñ–µ",
    "–ö–æ—Ñ–µ–π–Ω–∏",
    "–ö–æ–Ω–¥–∏—Ç–µ—Ä—Å–∫–∏–µ –∏ –ø–µ–∫–∞—Ä–Ω–∏",
    "–¢–æ—Ä–≥–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã",
    "–ú–µ—Å—Ç–∞ –¥–ª—è —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏—è"
]

def load_category_embeddings():
    print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
    embeddings = get_embeddings(category_names)
    
    if not embeddings:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞–∫ fallback
        import numpy as np
        random_embeddings = np.random.randn(len(category_names), 384).tolist()
        print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç")
        return torch.tensor(random_embeddings)
    
    print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω—ã, —Ä–∞–∑–º–µ—Ä: {len(embeddings)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
    try:
        if isinstance(embeddings, list) and len(embeddings) > 0:
            return torch.tensor(embeddings)
        else:
            raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞: {e}")
        # Fallback: —Å–ª—É—á–∞–π–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        import numpy as np
        return torch.tensor(np.random.randn(len(category_names), 384).tolist())

category_embeddings = load_category_embeddings()

def define_categories(text, similarity_threshold=0.3, min_categories=2, max_categories=5):
    print(f"üéØ –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{text}'")
    
    if category_embeddings is None:
        print("‚ùå –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        return []
    
    query_emb = get_embeddings(text)
    if not query_emb:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞")
        return []
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
    try:
        if isinstance(query_emb[0], list):
            query_emb_tensor = torch.tensor(query_emb[0]).unsqueeze(0)
        else:
            query_emb_tensor = torch.tensor(query_emb).unsqueeze(0)
            
        similarities = util.cos_sim(query_emb_tensor, category_embeddings)[0]
        sorted_indices = torch.argsort(similarities, descending=True).tolist()
        sorted_scores = similarities[sorted_indices].tolist()

        found = []
        for idx, score in zip(sorted_indices, sorted_scores):
            if score >= similarity_threshold:
                found.append((idx + 1, score))
            if len(found) >= max_categories:
                break

        if len(found) < min_categories:
            for idx, score in zip(sorted_indices, sorted_scores):
                if (idx + 1, score) not in found:
                    found.append((idx + 1, score))
                if len(found) >= min_categories:
                    break

        print(f"üéØ –ù–∞–π–¥–µ–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è '{text}': {found}")
        return found[:max_categories]
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏: {e}")
        return []

def get_candidate_places(query, ds):
    print(f"üîç –ò—â–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
    top_categories_with_score = define_categories(query)
    top_categories_ids = [cid for cid, score in top_categories_with_score]
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∫ —Å—Ç—Ä–æ–∫–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    if not top_categories_ids:
        print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–µ—Å—Ç–∞")
        if ds is not None and len(ds) > 0:
            return ds.sample(min(5, len(ds))).copy()
        else:
            return pd.DataFrame()
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –æ–±–∞ —Ç–∏–ø–∞ –∫ —Å—Ç—Ä–æ–∫–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    ds_category_str = ds['category_id'].astype(str)
    top_categories_str = [str(cid) for cid in top_categories_ids]
    
    candidate_places = ds[ds_category_str.isin(top_categories_str)].copy()
    score_dict = {cid: score for cid, score in top_categories_with_score}
    candidate_places['score'] = candidate_places['category_id'].astype(str).apply(lambda x: score_dict.get(int(x), 0))
    
    print(f"üìç –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidate_places)}")
    if len(candidate_places) > 0:
        print(f"üìã –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–µ—Å—Ç: {candidate_places['title'].head(3).tolist()}")
    
    return candidate_places

def find_place_in_dataset(place_name, candidate_places):
    """–ù–∞—Ö–æ–¥–∏—Ç –º–µ—Å—Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å —É—á–µ—Ç–æ–º –Ω–µ—á–µ—Ç–∫–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è"""
    place_name_clean = place_name.lower().strip()
    
    # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    exact_match = candidate_places[
        candidate_places['title'].str.lower() == place_name_clean
    ]
    if not exact_match.empty:
        return exact_match.iloc[0]
    
    # 2. –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (—Å–æ–¥–µ—Ä–∂–∏—Ç)
    partial_match = candidate_places[
        candidate_places['title'].str.lower().str.contains(place_name_clean, na=False)
    ]
    if not partial_match.empty:
        return partial_match.iloc[0]
    
    # 3. –ü–æ—Ö–æ–∂–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º)
    place_keywords = set(place_name_clean.split())
    best_match = None
    best_score = 0
    
    for _, candidate in candidate_places.iterrows():
        candidate_title = candidate['title'].lower()
        candidate_words = set(candidate_title.split())
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –ø–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—é —Å–ª–æ–≤
        common_words = place_keywords.intersection(candidate_words)
        score = len(common_words) / max(len(place_keywords), 1)
        
        if score > best_score and score > 0.3:  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
            best_score = score
            best_match = candidate
    
    return best_match

categories_time = {
    1: 15, 2: 40, 3: 15, 4: 40, 5: 30, 6: 40, 7: 40, 8: 120, 
    9: 10, 10: 15, 11: 40, 12: 30, 13: 15, 14: 40, 15: 60
}

@flask_app.route('/generate_route', methods=['POST', 'OPTIONS'])
def generate_route():
    logger.info("üöÄ generate_route called")

    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        return response

    try:
        data = request.get_json()
        if not data:
            print("‚ùå –ù–µ—Ç JSON –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–ø—Ä–æ—Å–µ")
            return jsonify({'error': 'No JSON data provided'}), 400

        query = data.get('query')
        hours = data.get('hours')
        minutes = data.get('minutes')
        startPoint = data.get('startPoint')

        print(f"üì® –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: query='{query}', hours={hours}, minutes={minutes}, startPoint='{startPoint}'")

        if not query:
            print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç query –≤ –∑–∞–ø—Ä–æ—Å–µ")
            return jsonify({'error': 'Query is required'}), 400

        try:
            hours = int(hours) if hours is not None else 0
            minutes = int(minutes) if minutes is not None else 0
            total_minutes = hours * 60 + minutes
            if total_minutes <= 0:
                total_minutes = 180
            userTime = total_minutes
        except (ValueError, TypeError) as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            total_minutes = 180
            userTime = total_minutes

        print(f"‚è± –†–∞—Å—Å—á–∏—Ç–∞–Ω–æ –æ–±—â–µ–µ –≤—Ä–µ–º—è: {total_minutes} –º–∏–Ω—É—Ç")

        ds = load_dataset()
        if ds is None:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç")
            return jsonify({'error': 'Failed to load dataset'}), 500

        if len(ds) == 0:
            print("‚ùå –î–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç–æ–π")
            return jsonify({'error': 'Dataset is empty'}), 500

        # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞
        candidate_places = get_candidate_places(query, ds)
        
        if candidate_places.empty:
            print("‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–µ—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞")
            candidate_places = ds.sample(min(5, len(ds))).copy()
        
        print(f"üìç –û—Ç–æ–±—Ä–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞: {len(candidate_places)}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è RouteExplainer
        places_for_explainer = []
        for _, place in candidate_places.head(10).iterrows():
            places_for_explainer.append({
                'name': place['title'],
                'description': place.get('description', ''),
                'category_id': place['category_id'],
                'visit_duration': categories_time.get(place['category_id'], 30)
            })

        print(f"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –º–µ—Å—Ç –¥–ª—è RouteExplainer: {len(places_for_explainer)}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º RouteExplainer –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∞
        route = route_explainer.create_route(
            places=places_for_explainer,
            user_interests=[query],
            total_duration=total_minutes,
            current_location=startPoint
        )

        print(f"üó∫ RouteExplainer –≤–µ—Ä–Ω—É–ª –º–∞—Ä—à—Ä—É—Ç: {route['route_name']}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        result_places = []
        for place in route['places']:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –º–µ—Å—Ç
            original_place = find_place_in_dataset(place['name'], candidate_places)
            
            if original_place is not None:
                try:
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                    coord_str = original_place['coordinate']
                    if 'POINT' in str(coord_str):
                        coords = str(coord_str).replace("POINT(", "").replace(")", "").split()
                    else:
                        coords = str(coord_str).split()
                    
                    if len(coords) >= 2:
                        lat, lon = float(coords[0]), float(coords[1])
                    else:
                        lat, lon = 56.326887, 44.005986  # –¶–µ–Ω—Ç—Ä –ù–ù –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        
                    result_places.append({
                        "title": place['name'],
                        "address": original_place.get('address', ''),
                        "coord": [lat, lon],
                        "description": original_place.get('description', ''),
                        "reason": place['reason'],
                        "time": place['duration']
                    })
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è {place['name']}: {e}")
                    result_places.append({
                        "title": place['name'],
                        "address": original_place.get('address', ''),
                        "coord": [56.326887, 44.005986],
                        "description": original_place.get('description', ''),
                        "reason": place['reason'],
                        "time": place['duration']
                    })
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
                result_places.append({
                    "title": place['name'],
                    "address": "",
                    "coord": [56.326887, 44.005986],
                    "description": "",
                    "reason": place['reason'],
                    "time": place['duration']
                })

        total_h = route['total_duration'] // 60
        total_m = route['total_duration'] % 60
        totalTime = f"{total_h} —á {total_m} –º–∏–Ω"

        result = {
            "startPoint": startPoint,
            "places": result_places,
            "totalTime": totalTime,
            "route_name": route.get('route_name', '–ú–∞—Ä—à—Ä—É—Ç –ø–æ –ù–∏–∂–Ω–µ–º—É –ù–æ–≤–≥–æ—Ä–æ–¥—É'),
            "explanation": route.get('explanation', ''),
            "timeline": route.get('timeline', ''),
            "userTime": userTime
        }

        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç: {len(result_places)} –º–µ—Å—Ç, –≤—Ä–µ–º—è: {totalTime}")
        response = jsonify(result)
        return response

    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ generate_route: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': 'Internal server error'}), 500

def test1():
    test_queries = [
        "–•–æ—á—É –ø—Ä–æ–≥—É–ª—è—Ç—å—Å—è –ø–æ –ø–∞—Ä–∫—É –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–∞–º—è—Ç–Ω–∏–∫–∏",
        "–ò—â—É —Ö–æ—Ä–æ—à–∏–π —Ä–µ—Å—Ç–æ—Ä–∞–Ω —Å –∫–æ—Ñ–µ –∏ –¥–µ—Å–µ—Ä—Ç–∞–º–∏",
        "–ü–æ—Å–µ—Ç–∏—Ç—å –º—É–∑–µ–π –∏ –≤—ã—Å—Ç–∞–≤–∫—É –∏—Å–∫—É—Å—Å—Ç–≤–∞",
        "–ü—Ä–æ–≥—É–ª—è—Ç—å—Å—è –ø–æ –Ω–∞–±–µ—Ä–µ–∂–Ω–æ–π –í–æ–ª–≥–∏",
        "–ß—Ç–æ-—Ç–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ"
    ]
    for query in test_queries:
        categories_found = define_categories(query)
        print(f"–ó–∞–ø—Ä–æ—Å: {query}")
        for cat_id, score in categories_found:
            label = category_names[cat_id - 1]
            if score is not None:
                print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è {cat_id}: {label}, —Å—Ö–æ–∂–µ—Å—Ç—å = {score:.3f}")
            else:
                print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏—è {cat_id}: {label} (fallback)")
        print("-" * 40)

def test2():
    ds = load_dataset()
    query="–•–æ—á—É –ø—Ä–æ–≥—É–ª—è—Ç—å—Å—è –ø–æ –ø–∞—Ä–∫—É –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–∞–º—è—Ç–Ω–∏–∫–∏"
    candidates = get_candidate_places(query, ds)
    print("–í—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∞:")
    print(candidates[['title', 'category_id', 'score']].sort_values(by='score', ascending=False))

def main():
    token = get_bot_token()
    app = Application.builder().token(token).build()

    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    port = int(os.environ.get('PORT', 10000))
        
    logger.info("Bot is running from Render.com")

    Thread(target=lambda: flask_app.run(host="0.0.0.0", port=port, debug=False)).start()
        
    app.run_polling()

if __name__ == "__main__":

    main()

